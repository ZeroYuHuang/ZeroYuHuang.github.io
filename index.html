<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zeyu Huang</title>

  <meta name="author" content="Zeyu Huang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zeyu Huang</name>
              </p>
              <p>
                I am a a PhD student (2024.01 - Now) at the University of Edinburgh. I am very lucky to be supervised by <a href="https://ivan-titov.org/">Ivan Titov</a> and <a href="https://ducdauge.github.io/">Edoardo M. Ponti</a>. I am currently a Student Researcher at <a href="https://deepmind.google/"> Google DeepMind</a> London, advised by <a href="https://ranzato.github.io/">Marc'Aurelio Ranzato</a> and <a href="https://scholar.google.com/citations?hl=en&user=VBkk_NoAAAAJ&view_op=list_works&sortby=pubdate">Adhiguna Kuncoro</a>.
              </p>                
              <p style="text-align:center">
                <a href="mailto:zeroy.huang@gmail.com">Email</a> &nbsp/&nbsp
                <a href="Resume_Aug_2025.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=EWU88_YAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/ZeroYuHuang">GitHub</a> &nbsp/&nbsp
                <a href="https://x.com/ZeroyuHuang">Twitter</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/%E6%B3%BD%E5%AE%87-%E9%BB%84-2b288025b/?locale=en_US">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:33%;max-width:33%">
              <a href="images/zeyu.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/zeyu.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <heading>Research</heading>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <p>
                I am broadly interested in different kinds of <strong>learning</strong> algorithms, with a particular interest in designing <strong>general lifelong learners</strong> that can efficiently adapt to new tasks and environments over time.
              </p>
              <p>
                My current research mainly focuses on large language models (LLMs). I have been working on Model Editing, Mixture of Experts (MoE), and LLMs for Reinforcement Learning (RL). If you are interested in these topics, please feel free to reach out to me!!!
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Selected publications and preprints</heading>
          <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2507.01679">
                <papertitle>Bending Supervised and Reinforcement Fine-Tuning with Prefix Sampling </papertitle>
              </a>
              <br>
              <strong>Zeyu Huang</strong>, Tianhao Cheng, Zihan Qiu, Zili Wang, Yinghui Xu, Edoardo M Ponti, Ivan Titov.
              <br>
                <em>arXiv</em>, 2025 | <a href="https://github.com/ZeroYuHuang/prefix_rft">code</a>
              <br>
            </td>
          </tr>
          <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2506.02921">
            <papertitle>A Controllable Examination for Long-Context Language Models </papertitle>
            </a>
            <br>
            Yijun Yang*, <strong>Zeyu Huang*</strong>, Wenhao Zhu, Zihan Qiu, Fei Yuan, Jeff Z Pan, Ivan Titov.
            <br>
            <em>arXiv</em>, 2025 | <a href="https://github.com/Thomasyyj/LongBio-Benchmark">code</a>
            <br> 
            </td>
          </tr>
          <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/pdf/2505.06708">
            <papertitle>Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free</papertitle>
            </a>
            <br>
            Zihan Qiu*, Zekun Wang*, Bo Zheng*, <strong>Zeyu Huang*</strong>, Kaiyue Wen, Songlin Yang, Rui Men, Le Yu, Fei Huang, Suozhi Huang, Dayiheng Liu, Jingren Zhou, Junyang Lin
            <br>
            <em>arXiv</em>, 2025 | <a href="https://github.com/qiuzh20/gated_attention">code</a>
            <br> 
            </td>
          </tr>
          <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2501.11873">
            <papertitle>Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models</papertitle>
            </a>
            <br>
            Zihan Qiu*, <strong>Zeyu Huang*</strong>, Bo Zheng*, Kaiyue Wen, Zekun Wang, Rui Men, Ivan Titov, Dayiheng Liu, Jingren Zhou, Junyang Lin
            <br>
            <em>ACL 2025 Main</em>
            <br>
            </td>
          </tr>
          <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2409.17407">
            <papertitle>Post-hoc Reward Calibration: A Case Study on Length Bias</papertitle>
            </a>
            <br>
            <strong>Zeyu Huang</strong>, Zihan Qiu, Zili Wang, Edoardo M. Ponti, Ivan Titov
            <br>
            <em>ICLR 2025</em> | <a href="https://github.com/ZeroYuHuang/Reward-Calibration">code</a>
            <br>
            </td>
          </tr>
          <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2408.06793">
            <papertitle>Layerwise Recurrent Router for Mixture-of-Experts</papertitle>
            </a>
            <br>
            Zihan Qiu*, <strong>Zeyu Huang*</strong>, Shuang Cheng, Yizhi Zhou, Zili Wang, Ivan Titov, Jie Fu
            <br>
            <em>ICLR 2025</em> | <a href="https://github.com/qiuzh20/RMoE">code</a>
            <br>
            </td>
          </tr>
          <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2310.10908">
            <papertitle>Unlocking Emergent Modularity in Large Language Models</papertitle>
            </a>
            <br>
            Zihan Qiu*, <strong>Zeyu Huang</strong>, Shuang Cheng, Yizhi Zhou, Zili Wang, Ivan Titov, Jie Fu
            <br>
            <em>NAACL 2024, üèÜ<span style="color: red;">Outstanding Paper</span></em> | <a href="https://github.com/qiuzh20/EMoE">code</a>
            <br>
            </td>
          </tr>
          <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
            <a href=https://arxiv.org/abs/2301.09785">
            <papertitle>Transformer-Patcher: One Mistake worth One Neuron</papertitle>
            </a>
            <br>
            <strong>Zeyu Huang</strong>, Yikang Shen, Xiaofeng Zhang, Jie Zhou, Wenge Rong, Zhang Xiong
            <br>
            <em>ICLR 2023</em> | <a href="https://github.com/ZeroYuHuang/Transformer-Patcher">code</a>
            <br>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                
                <a href="https://jonbarron.info/">website credits</a>
                
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>